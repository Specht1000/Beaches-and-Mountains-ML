# Importando bibliotecas necessárias
import pandas as pd
import numpy as np
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score, confusion_matrix
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Optional
#para o primeiro algoritmo
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Carrega o dataset de treino
data_train = pd.read_csv('treino.csv')
data_train.head()
# Criação de Features de treino
data_train['Average_Proximity'] = (data_train['Proximity_to_Mountains'] + data_train['Proximity_to_Beaches']) / 2
data_train['Total_Travel_Expenditure'] = data_train['Travel_Frequency'] * data_train['Vacation_Budget']
data_train['Income_Per_Age'] = data_train['Income'] / data_train['Age']
data_train['Is_Graduate'] = data_train['Education_Level'].apply(lambda x: 1 if x in ['bachelor', 'master', 'doctorate'] else 0)

# Criação de novas features
data_train['Income_Age_Ratio'] = data_train['Income'] / data_train['Age']
data_train['Budget_Per_Trip'] = data_train['Vacation_Budget'] / (data_train['Travel_Frequency'] + 1)
data_train['Total_Distance'] = data_train['Proximity_to_Mountains'] + data_train['Proximity_to_Beaches']
data_train['Travel_Frequency_Budget_Interaction'] = data_train['Travel_Frequency'] * data_train['Vacation_Budget']

# Classificação da renda em categorias
bins = [0, 30000, 60000, 90000, np.inf]
labels = ['Baixa', 'Média', 'Alta', 'Muito Alta']
data_train['Income_Category'] = pd.cut(data_train['Income'], bins=bins, labels=labels)
# Carrega o dataset de teste
data_test = pd.read_csv('teste.csv')
data_test.head()
# Criação de Features de teste
data_test['Average_Proximity'] = (data_test['Proximity_to_Mountains'] + data_test['Proximity_to_Beaches']) / 2
data_test['Total_Travel_Expenditure'] = data_test['Travel_Frequency'] * data_test['Vacation_Budget']
data_test['Income_Per_Age'] = data_test['Income'] / data_test['Age']
data_test['Is_Graduate'] = data_test['Education_Level'].apply(lambda x: 1 if x in ['bachelor', 'master', 'doctorate'] else 0)
# Criação de novas features para o conjunto de teste (repita as mesmas operações)
data_test['Income_Age_Ratio'] = data_test['Income'] / data_test['Age']
data_test['Budget_Per_Trip'] = data_test['Vacation_Budget'] / (data_test['Travel_Frequency'] + 1)
data_test['Total_Distance'] = data_test['Proximity_to_Mountains'] + data_test['Proximity_to_Beaches']
data_test['Travel_Frequency_Budget_Interaction'] = data_test['Travel_Frequency'] * data_test['Vacation_Budget']
data_test['Income_Category'] = pd.cut(data_test['Income'], bins=bins, labels=labels)
# Verifica a dimensão dos dados de treino e teste
print(f'Dimensão dos dados de treino: {data_train.shape}\n')
print(f'Dimensão dos dados de teste: {data_test.shape}\n')
# Início da normalização de todos os dados
# Identificando colunas numéricas e categóricas
numeric_cols = data_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = data_train.select_dtypes(include=['object']).columns.tolist()
# Inicializando o scaler
scaler = StandardScaler()
# Normalizando os dados numéricos de treino , com o Z-Score Normalization ou Standardization.
data_train[numeric_cols] = scaler.fit_transform(data_train[numeric_cols])
# Normalizando os dados numéricos de teste (usando os parâmetros do treino) 
data_test[numeric_cols] = scaler.transform(data_test[numeric_cols])
# Aplicar One-Hot Encoding nas variáveis categóricas de treino e teste
data_train = pd.get_dummies(data_train, columns=categorical_cols, drop_first=True)
data_test = pd.get_dummies(data_test, columns=categorical_cols, drop_first=True)
# Garantir que as colunas nos conjuntos de treino e teste sejam as mesmas
data_train, data_test = data_train.align(data_test, join='left', axis=1, fill_value=0)
# Verificando a normalização e a codificação 
print("Dados de treino após normalização e One-Hot Encoding:")
print(data_train.describe())

print("Dados de teste após normalização e One-Hot Encoding:")
print(data_test.describe())
# Função para visualizar dados numéricos e categóricos do conjunto de dados
def analise_grafica(dataframe, dataset_name="Dataset"):
    # Separar colunas numéricas e categóricas
    numeric_columns = dataframe.select_dtypes(include=['int64', 'float64']).columns
    categorical_columns = dataframe.select_dtypes(include=['object', 'category']).columns
    
    print(f"Análise Gráfica para {dataset_name}")
    
    # Histograma para variáveis numéricas
    dataframe[numeric_columns].hist(bins=20, figsize=(15, 10))
    plt.suptitle(f'Distribuição das Variáveis Numéricas - {dataset_name}', fontsize=16)
    plt.show()

    # Gráficos de barras para variáveis categóricas
    num_cols = 3  # Número de colunas na plotagem
    num_rows = (len(categorical_columns) + num_cols - 1) // num_cols  # Número de linhas necessárias
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 5))
    axes = axes.flatten()

    for i, col in enumerate(categorical_columns):
        sns.countplot(data=dataframe, x=col, ax=axes[i], palette="muted", hue=col, dodge=False, legend=False)
        axes[i].set_title(f'Distribuição de {col}')
        axes[i].tick_params(axis='x', rotation=45)

    # Remover subplots não utilizados
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

    # Heatmap de correlação para variáveis numéricas
    plt.figure(figsize=(12, 10))
    sns.heatmap(dataframe[numeric_columns].corr(), annot=True, fmt=".2f", cmap="coolwarm")
    plt.title(f'Mapa de Correlação das Variáveis Numéricas - {dataset_name}')
    plt.show()
### Explicação dos Termos Estatísticos

- **count**: Número total de observações não nulas para a coluna.
- **unique**: Número de valores únicos na coluna (somente para dados categóricos).
- **top**: O valor mais frequente (somente para dados categóricos).
- **freq**: Frequência do valor mais frequente (somente para dados categóricos).
- **mean**: Média aritmética dos valores (somente para dados numéricos).
- **std**: Desvio padrão dos valores, indicando a dispersão em torno da média (somente para dados numéricos).
- **min**: Valor mínimo encontrado na coluna (somente para dados numéricos).
- **25% (1º quartil)**: O valor abaixo do qual 25% dos dados estão (somente para dados numéricos).
- **50% (mediana)**: O valor central que divide os dados em duas partes iguais (somente para dados numéricos).
- **75% (3º quartil)**: O valor abaixo do qual 75% dos dados estão (somente para dados numéricos).
- **max**: Valor máximo encontrado na coluna (somente para dados numéricos).
# Estatísticas sobre as variáveis numéricas de treino
data_train.describe()
# Análise gráfca do treino
analise_grafica(data_train, "treino.csv")
# Estatísticas sobre as variáveis numéricas de teste
data_test.describe()
# Análise gráfca do teste
analise_grafica(data_test, "teste.csv")
# Lista de variáveis categóricas
colunas_cat = data_train.select_dtypes(include=['object']).columns.tolist()

# Estatísticas sobre as variáveis categóricas
for coluna in colunas_cat:
    print(f'### Coluna <{coluna}> ###')
    print(data_train[coluna].value_counts())
    print('-' * 40)
# Lista de variáveis categóricas
colunas_cat = data_test.select_dtypes(include=['object']).columns.tolist()

# Estatísticas sobre as variáveis categóricas
for coluna in colunas_cat:
    print(f'### Coluna <{coluna}> ###')
    print(data_test[coluna].value_counts())
    print('-' * 40)
data_train.info()
data_test.info()
# Verificando dados nulos do treino
print('Colunas com dados nulos:')
display(data_train.isnull().sum()[data_train.isnull().sum() > 0])
# Verificando dados nulos do teste
print('Colunas com dados nulos:')
display(data_test.isnull().sum()[data_test.isnull().sum() > 0])
# Definir a conversão para variáveis categóricas ordinais
conversao_variaveis = {
    'Gender': {
        'non-binary': 0,
        'female': 1,
        'male': 2
    },
    'Education_Level': {
        'high school': 1,
        'bachelor': 2,
        'master': 3,
        'doctorate': 4
    },
    'Preferred_Activities': {
        'hiking': 1,
        'skiing': 2,
        'swimming': 3,
        'sunbathing': 4
    },
    'Location': {
        'rural': 1,
        'suburban': 2,
        'urban': 3
    },
    'Favorite_Season': {
        'spring': 1,
        'fall': 2,
        'winter': 3,
        'summer': 4
    },
    'Pets': {
        0: 'No',  
        1: 'Yes'  
    },
    'Environmental_Concerns': {
        0: 'No',  
        1: 'Yes'  
    }
}

# Aplicar a conversão
data_train.replace(conversao_variaveis, inplace=True)
data_test.replace(conversao_variaveis, inplace=True)

# Visualizar uma amostra para confirmar a conversão
data_train.sample(5)
data_test.sample(5)

# Listar as variáveis categóricas (excluindo a variável alvo, se for categórica)
cols_cat_train = data_train.select_dtypes(include='object').columns.tolist()
cols_cat_test = data_train.select_dtypes(include='object').columns.tolist()

# Aplicar OneHotEncoding nas variáveis categóricas de treino e teste
data_train = pd.get_dummies(data_train, columns=cols_cat_train, drop_first=True)
data_test = pd.get_dummies(data_test, columns=cols_cat_test, drop_first=True)

# Garantir que as colunas nos conjuntos de treino e teste sejam as mesmas
# Isso é útil caso algumas categorias estejam ausentes em um dos conjuntos
data_train, data_test = data_train.align(data_test, join='left', axis=1, fill_value=0)

# Exibir uma amostra dos dados para verificar o resultado
print("Amostra dos dados de treino com OneHotEncoding:")
display(data_train.head())

print("Amostra dos dados de teste com OneHotEncoding:")
display(data_test.head())
print("Valores nulos do treino")

# Imputando os valores nulos com a média para colunas numéricas
numeric_cols = data_train.select_dtypes(include=['int64', 'float64']).columns
data_train[numeric_cols] = data_train[numeric_cols].fillna(data_train[numeric_cols].mean())

# Verifica valores nulos novamente
print(data_train.isnull().sum())
print("Valores nulos do teste")

# Imputando os valores nulos com a média para colunas numéricas
numeric_cols = data_test.select_dtypes(include=['int64', 'float64']).columns
data_test[numeric_cols] = data_test[numeric_cols].fillna(data_test[numeric_cols].mean())

# Verifica valores nulos novamente
data_test.isnull().sum()
# Separar as variáveis independentes (X) e dependente (y) nos conjuntos de treino e teste
X = data_train.drop(columns=['Preference'])
y = data_train['Preference']

# Dividir os dados em treino e teste com stratify
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

# Verificar as proporções de classes no conjunto de treino
print("### Proporção de Classes em Treino ###")
print(f"Porcentagem de entradas Classe 0: {y_train.value_counts(normalize=True).values[0] * 100:.2f}%")
print(f"Porcentagem de entradas Classe 1: {y_train.value_counts(normalize=True).values[1] * 100:.2f}%")
print()

# Verificar as proporções de classes no conjunto de teste
print("### Proporção de Classes em Teste ###")
print(f"Porcentagem de entradas Classe 0: {y_test.value_counts(normalize=True).values[0] * 100:.2f}%")
print(f"Porcentagem de entradas Classe 1: {y_test.value_counts(normalize=True).values[1] * 100:.2f}%")
# Análise e Tratamento de Valores Faltantes
def preprocess_data(data):
    imputer = SimpleImputer(strategy='most_frequent')
    data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)
    
    # Codificação de variáveis categóricas
    data = pd.get_dummies(data, columns=['Gender', 'Education_Level', 'Preferred_Activities', 'Location', 'Favorite_Season'], drop_first=True)
    
    # Normalização das features numéricas
    scaler = StandardScaler()
    numeric_features = ['Age', 'Income', 'Travel_Frequency', 'Vacation_Budget', 'Proximity_to_Mountains', 'Proximity_to_Beaches']
    data[numeric_features] = scaler.fit_transform(data[numeric_features])
    
    return data
# Pré-processar dados de treino e teste
data_train = preprocess_data(data_train)
data_test = preprocess_data(data_test)

# Separando features e target
X_train = data_train.drop(columns=['Preference'])
y_train = data_train['Preference']
X_test = data_test.drop(columns=['Preference'])
y_test = data_test['Preference']

# Seleção de features
selector = SelectKBest(f_classif, k=10)
X_train = selector.fit_transform(X_train, y_train)
X_test = selector.transform(X_test)

# Obter os nomes das colunas selecionadas
selected_columns = data_train.drop(columns=['Preference']).columns[selector.get_support()]

# Transformar X_train e X_test de volta em DataFrames
X_train = pd.DataFrame(X_train, columns=selected_columns)
X_test = pd.DataFrame(X_test, columns=selected_columns)
def performance_modelo_classificacao(model, X_train, X_test, y_train, y_test, flag=True):
    # Lista para armazenar os resultados de Treino e Teste
    score_list = []

    # Predição em Treino e Teste
    pred_train = model.predict(X_train)
    pred_test = model.predict(X_test)

    # Acurácia do modelo
    train_acc = accuracy_score(y_train, pred_train)
    test_acc = accuracy_score(y_test, pred_test)

    # Recall do modelo
    train_recall = recall_score(y_train, pred_train)
    test_recall = recall_score(y_test, pred_test)

    # Precisão do modelo
    train_prec = precision_score(y_train, pred_train)
    test_prec = precision_score(y_test, pred_test)

    # F1-Score do modelo
    train_f1 = f1_score(y_train, pred_train)
    test_f1 = f1_score(y_test, pred_test)

    # Popula a lista
    score_list.extend((train_acc, test_acc, train_recall, test_recall, train_prec, test_prec, train_f1, test_f1))

    # Imprime os resultados se flag=True
    if flag:
        print(f'Acurácia na base de Treino: {train_acc:.4f}')
        print(f'Acurácia na base de Teste: {test_acc:.4f}')
        print(f'\nRecall na base de Treino: {train_recall:.4f}')
        print(f'Recall na base de Teste: {test_recall:.4f}')
        print(f'\nPrecisão na base de Treino: {train_prec:.4f}')
        print(f'Precisão na base de Teste: {test_prec:.4f}')
        print(f'\nF1-Score na base de Treino: {train_f1:.4f}')
        print(f'F1-Score na base de Teste: {test_f1:.4f}')

    # Retorna a lista de valores de métricas para Treino e Teste
    return score_list
# Função para exibir a matriz de confusão
def matriz_confusao(model, X, y_actual, labels=(1, 0)):
    y_predict = model.predict(X)
    cm = confusion_matrix(y_actual, y_predict, labels=[0, 1])
    df_cm = pd.DataFrame(cm, index=['Real - Não (0)', 'Real - Sim (1)'],
                         columns=['Previsto - Não (0)', 'Previsto - Sim (1)'])
    group_counts = [f'{value:.0f}' for value in cm.flatten()]
    group_percentages = [f'{value:.2f}%' for value in (cm.flatten() / np.sum(cm)) * 100]
    labels = [f'{v1}\n{v2}' for v1, v2 in zip(group_counts, group_percentages)]
    labels = np.asarray(labels).reshape(2, 2)
    plt.figure(figsize=(10, 7))
    sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')
    plt.xlabel('Classe Prevista', fontweight='bold')
    plt.ylabel('Classe Real', fontweight='bold')
    plt.show()
# Instanciando o modelo de Árvore de Decisão
arvore_d = DecisionTreeClassifier(criterion="entropy", random_state=1)

# Treinando o modelo
arvore_d.fit(X_train, y_train)

# Avaliando o modelo no conjunto de treino e teste
print("### Avaliação do Modelo de Árvore de Decisão ###")
arvore_d_scores = performance_modelo_classificacao(arvore_d, X_train, X_test, y_train, y_test)
# Matriz de Confusão de treino
matriz_confusao(arvore_d, X_train, y_train)
# Matriz de Confusão de teste
matriz_confusao(arvore_d, X_test, y_test)
# Plot da árvore
feature_names = list(X_train.columns)

plt.figure(figsize=(20, 30))
tree.plot_tree(arvore_d, feature_names=feature_names, filled=True,
            fontsize=9, node_ids=True, class_names=True);
# Instanciando o modelo de Árvore de Decisão com Poda
arvore_d1 = DecisionTreeClassifier(criterion="entropy", random_state=1, max_depth=3)

# Treinando o modelo
arvore_d1.fit(X_train, y_train)

# Avaliando o modelo no conjunto de treino e teste
print("### Avaliação do Modelo de Árvore de Decisão ###")
arvore_d1_scores = performance_modelo_classificacao(arvore_d1, X_train, X_test, y_train, y_test)
# Matriz de Confusão de treino
matriz_confusao(arvore_d1, X_train, y_train)
# Matriz de Confusão de teste
matriz_confusao(arvore_d1, X_test, y_test)
feature_names = list(X_train.columns)

plt.figure(figsize=(15, 10))
tree.plot_tree(arvore_d1, feature_names=feature_names, filled=True,
            fontsize=9, node_ids=True, class_names=True);
# Carregando os dados
df_train = pd.read_csv('treino.csv', sep=',', encoding='iso-8859-1')
df_test = pd.read_csv('teste.csv', sep=',', encoding='iso-8859-1')

## Separando as variáveis independentes (X) e dependente (y) para o conjunto de treino
X_train = df_train[['Proximity_to_Mountains']]
y_train = df_train['Preference']   # Variável alvo

# Instanciando o modelo de Regressão Linear
modelo_linear = LinearRegression()

# Treinando o modelo com os dados de treino
modelo_linear.fit(X_train, y_train)

# Separando as variáveis independentes (X) e dependente (y) para o conjunto de teste
X_test = df_test[['Proximity_to_Mountains']]
y_test = df_test['Preference']   # Variável alvo

# Fazendo previsões com os dados de teste
y_pred = modelo_linear.predict(X_test)

# Avaliando o modelo
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'R² Score: {r2:.2f}')

# Visualizando os resultados
plt.scatter(X_test, y_test, color='blue', label='Dados Reais')
plt.plot(X_test, y_pred, color='red', label='Linha de Regressão')
plt.title('Regressão Linear Simples - Conjunto de Teste')
plt.xlabel('Frequência de Viagem')
plt.ylabel('Preferência')
plt.legend()
plt.show()
